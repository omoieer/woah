{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"本项目参考了squi2rel、MIOLOVERS等人的notebook，并成功支持deepdanbooru与xformers\n\n其中deepdanbooru用于根据已有图片反推出对应的tag；而xformers经过实测，在kaggle平台上可以显著降低GPU显存，大幅提升速度，并且不影响出图质量(根据目前测试看来，在其他参数与GPU设备都相同的情况下，出的图是完全一致的)。**注意，不同的GPU设备，出的图是会有差异的。**\n\n**不使用xformers，生成1280x960的图片(Euler, 28 steps, CFG Scale: 12):**\n\n在T4与P100机器上，无论是txt2img还是img2img都需要1分20秒以上，显存爆满\n\n**使用xformers，生成1280x960的图片(Euler, 28 steps, CFG Scale: 12):**\n\n在T4机器上，txt2img需要40秒，img2img需要30秒，显存仅占用3~6G\n\n在P100机器上，txt2img需要60秒，img2img需要50秒，显存仅占用3~6G","metadata":{}},{"cell_type":"code","source":"# install webui\n%cd /kaggle/working/\n!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n    \n# 选择一个可以正常使用的稳定版本commit\n# 最新版目前看不到进度条https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/6774\n%cd /kaggle/working/stable-diffusion-webui/\n!git checkout 9ef41df6f9043d58fbbeea1f06be8e5c8622248b","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# link Novelai model\n#!ln -s /kaggle/input/nai-pruned/animefull-final-pruned.ckpt /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animefull-final-pruned.ckpt\n#!ln -s /kaggle/input/nai-pruned/v1-inference.yaml           /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animefull-final-pruned.yaml\n#!ln -s /kaggle/input/nai-pruned/animevae.pt                 /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animefull-final-pruned.vae.pt\n\n# link anything-v3.0 model\n#!ln -s /kaggle/input/anythingv30/Anything-V3.0.ckpt          /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/Anything-V3.0.ckpt\n#!ln -s /kaggle/input/anythingv30/Anything-V3.0.vae.pt        /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/Anything-V3.0.vae.pt\n#!ln -s /kaggle/input/anythingv30/Anything-V3.0-pruned.ckpt   /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/Anything-V3.0-pruned.ckpt\n\n# link momoko model\n!ln -s /kaggle/input/momoko/momoko-e.ckpt               /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/momoko-e.ckpt\n!ln -s /kaggle/input/momoko/momoko-p.ckpt               /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/momoko-p.ckpt\n!ln -s /kaggle/input/momoko/momoko-any3.0.ckpt          /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/momoko-any3.0.ckpt\n\n# link 64-in-1 model\n#!ln -s \"/kaggle/input/64-in-1/64in1 推荐使用原版vae 这个可以按本模型0.9 3d模型0.1融合改善人物.ckpt\" /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/64-in-1.ckpt\n\n# download AbyssOrangeMix2 model\n#!wget https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_sfw.safetensors -O /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/AbyssOrangeMix2_sfw.safetensors\n#!wget https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -O /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/AbyssOrangeMix2_hard.safetensors\n#!wget https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_nsfw.safetensors -O /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/AbyssOrangeMix2_nsfw.safetensors\n\n# link hypernetwork\n!ln -s /kaggle/input/nai-pruned/modules/         /kaggle/working/stable-diffusion-webui/models/hypernetworks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show gpu info\n!nvidia-smi\n\n# temporary fix for now, deepdanbooru error DNN library not found.\n!apt install -y libcudnn8 --allow-change-held-packages\n\n# install xformers\n!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n\nfrom subprocess import getoutput\ns = getoutput('nvidia-smi')\nif 'T4' in s:\n    !pip install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.14/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\nelif 'P100' in s:\n    !pip install https://github.com/Isotr0py/xformers-prebuild-wheels/raw/main/P100/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tag自动补全插件（可选）\n%cd /kaggle/working/stable-diffusion-webui/\n!git clone \"https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git\" extensions/tag-autocomplete\n%cd /kaggle/working/stable-diffusion-webui/extensions/tag-autocomplete\n!git checkout 7fdad1bf623f1df0af72404afc1031d1e8adfa99\n\n# 下载审美渐变插件（可选）\n%cd /kaggle/working/stable-diffusion-webui/\n!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients extensions/aesthetic-gradients\n%cd /kaggle/working/stable-diffusion-webui/extensions/aesthetic-gradients\n!git checkout 2624e5dd4902cb731287b426ad483e741ece85bb\n    \n# 下载历史记录/图像浏览器插件（可选）\n%cd /kaggle/working/stable-diffusion-webui/\n!git clone https://github.com/yfszzx/stable-diffusion-webui-images-browser extensions/images-browser\n%cd /kaggle/working/stable-diffusion-webui/extensions/images-browser\n!git checkout a42c7a30181636a05815e62426d5eff4d3340529\n    \n# 中文UI界面翻译插件（可选）\n%cd /kaggle/working/stable-diffusion-webui/\n!git clone https://github.com/dtlnor/stable-diffusion-webui-localization-zh_CN extensions/localization-zh_CN\n%cd /kaggle/working/stable-diffusion-webui/extensions/localization-zh_CN\n!git checkout 7d106b8c180159d3826b70d351448e947efd6bdd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Replicating NovelAI defaults**\n\nIt is possible to create outputs identical to NovelAI's current subscription service by doing the following:\n\n**Standard (Euler)**\n\n-Set the sampler to Euler (Not Euler A)\n\n-Use 28 Steps\n\n-Set CFG Scale to 11\n\n-Use **masterpiece, best quality** at the beginning of all positive prompts\n\n-Use **nsfw, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name** as the negative prompt\n(nsfw is optional, and toggled on the site)\n\n-In the Settings tab, change **Stop last layers of CLIP model** to 2 and apply\n\n**Euler-A Defaults**\n\nIf you want to replicate NovelAI Euler_a results, you must do the following alongside the defaults above:\n\n-Under Sampler Parameters in settings, set '**ETA Noise Seed Delta**' to 31337\n\nAnd you should be ready to prompt!\n\n如果部署上有什么疑问可以参考教程：https://rentry.org/voldy\n\n魔法咏唱：https://aitag.top/\n\n元素法典：https://docs.qq.com/doc/DWEpNdERNbnBRZWNL\n\n藏丹阁：https://docs.qq.com/doc/DY0lFeWZuVXRCdUJU","metadata":{}},{"cell_type":"code","source":"#launch\n%cd /kaggle/working/stable-diffusion-webui\n\n# hacks to load model in gpu\n!sed -i 's/map_location=None/map_location=\"cuda\"/g' /kaggle/working/stable-diffusion-webui/modules/sd_models.py\n\n# 使用最新版本的gradio时会有bug，无法正常工作，因此回退3.9版本\n# 参考https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/6210\n!sed -i 's/gradio==3.15.0/gradio==3.9.0/g' /kaggle/working/stable-diffusion-webui/requirements.txt\n\n!COMMANDLINE_ARGS=\"--share --xformers --deepdanbooru --gradio-debug --lowram --disable-safe-unpickle --gradio-auth balls:balls,undefeatable:sonic\" REQS_FILE=\"requirements.txt\" python launch.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 打包输出图片到/kaggle/working/outputs.tar内\n# make output images into /kaggle/working/outputs.tar\n%cd /kaggle/working/stable-diffusion-webui/\n!tar -cvf outputs.tar ./outputs ./log\n!mv ./outputs.tar ../\n\n# 仅打包在webui中选择了保存的图片\n!tar -cvf only_saved_img.tar ./log\n!mv ./only_saved_img.tar ../\n\n# 打包完后删除目录\n!rm -rf ./outputs ./log\n!mkdir ./outputs ./log","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}