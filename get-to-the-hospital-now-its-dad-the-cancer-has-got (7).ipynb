{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Make persistence to Files Only and execute the first cell **once**! Other sessions don't need it anymore.","metadata":{"_uuid":"7b37d41c-7644-4692-907c-fa73bcce1fc6","_cell_guid":"eb802aee-05fc-4a24-9e65-0a700201660c","trusted":true}},{"cell_type":"code","source":"!apt-get update -y\n!mkdir /kaggle/tmp\n!git -C /kaggle/tmp/ clone https://github.com/henk717/KoboldAI\n%cd /kaggle/tmp/KoboldAI/\n!git checkout 613b02e6f818dc4252884f8125c7197c28e3689b\n%cd /kaggle/\n!pip3 install pyngrok\n!pip3 install transformers\n!pip3 install --no-deps tensorflow-io\n#!pip3 install -i https://test.pypi.org/simple/ bitsandbytes-cudaXXX\n!apt -y install -qq aria2\n!pip3 install -r /kaggle/tmp/KoboldAI/requirements.txt","metadata":{"_uuid":"36838f80-da37-498b-8770-6edf06844b34","_cell_guid":"92c81b45-4973-4755-b9f7-e3e4d831ea5b","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-03T05:02:27.048489Z","iopub.execute_input":"2023-11-03T05:02:27.048784Z","iopub.status.idle":"2023-11-03T05:04:27.336345Z","shell.execute_reply.started":"2023-11-03T05:02:27.048757Z","shell.execute_reply":"2023-11-03T05:04:27.335277Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Get:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [1299 B]\nGet:2 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]       \nGet:3 https://packages.cloud.google.com/apt google-fast-socket InRelease [5015 B]\nHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nGet:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]        \nGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\nGet:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]      \nGet:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\nGet:9 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [545 kB]\nGet:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [591 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1279 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1455 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1419 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.9 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [78.3 kB]\nGet:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1013 kB]\nGet:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1392 kB]\nGet:19 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\nGet:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1186 kB]\nReading package lists... Done                                \nW: http://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Origin' value from 'gcsfuse-jessie' to 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal'\nE: Repository 'http://packages.cloud.google.com/apt gcsfuse-focal InRelease' changed its 'Label' value from 'gcsfuse-jessie' to 'namespaces/gcs-fuse-prod/repositories/gcsfuse-focal'\nN: This must be accepted explicitly before updates for this repository can be applied. See apt-secure(8) manpage for details.\nW: https://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nCloning into 'KoboldAI'...\nremote: Enumerating objects: 18988, done.\u001b[K\nremote: Counting objects: 100% (642/642), done.\u001b[K\nremote: Compressing objects: 100% (292/292), done.\u001b[K\nremote: Total 18988 (delta 386), reused 539 (delta 330), pack-reused 18346\u001b[K\nReceiving objects: 100% (18988/18988), 22.34 MiB | 23.25 MiB/s, done.\nResolving deltas: 100% (13144/13144), done.\n/kaggle/tmp/KoboldAI\nNote: switching to '613b02e6f818dc4252884f8125c7197c28e3689b'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at 613b02e6 Worker main branch\n/kaggle\nCollecting pyngrok\n  Downloading pyngrok-7.0.0.tar.gz (718 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.7/718.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0)\nBuilding wheels for collected packages: pyngrok\n  Building wheel for pyngrok (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyngrok: filename=pyngrok-7.0.0-py3-none-any.whl size=21129 sha256=1acb94aeacadc2f051d0ed0e4629286cdc4204cb7293eb230505fa6d08eb2c06\n  Stored in directory: /root/.cache/pip/wheels/60/29/7b/f64332aa7e5e88fbd56d4002185ae22dcdc83b35b3d1c2cbf5\nSuccessfully built pyngrok\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.0.0\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: tensorflow-io in /opt/conda/lib/python3.10/site-packages (0.32.0)\nThe following additional packages will be installed:\n  libaria2-0 libc-ares2 libssh2-1\nThe following NEW packages will be installed:\n  aria2 libaria2-0 libc-ares2 libssh2-1\n0 upgraded, 4 newly installed, 0 to remove and 100 not upgraded.\nNeed to get 1622 kB of archives.\nAfter this operation, 5817 kB of additional disk space will be used.\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libc-ares2:amd64.\n(Reading database ... 113818 files and directories currently installed.)\nPreparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libssh2-1:amd64.\nPreparing to unpack .../libssh2-1_1.10.0-3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libssh2-1:amd64 (1.10.0-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libaria2-0:amd64.\nPreparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libaria2-0:amd64 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package aria2.\nPreparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking aria2 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libssh2-1:amd64 (1.10.0-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libaria2-0:amd64 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up aria2 (1.36.0-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for man-db (2.10.2-1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JCollecting git+https://github.com/VE-FORBRYDERNE/mkultra (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 25))\n  Cloning https://github.com/VE-FORBRYDERNE/mkultra to /tmp/pip-req-build-ck7x2tlm\n  Running command git clone --filter=blob:none --quiet https://github.com/VE-FORBRYDERNE/mkultra /tmp/pip-req-build-ck7x2tlm\n  Resolved https://github.com/VE-FORBRYDERNE/mkultra to commit ef544de73ec6a1a4bd55e824d0628fa0ef1323ac\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hIgnoring bitsandbytes: markers 'sys_platform == \"win32\"' don't match your environment\nCollecting git+https://github.com/0cc4m/hf_bleeding_edge/ (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 40))\n  Cloning https://github.com/0cc4m/hf_bleeding_edge/ to /tmp/pip-req-build-xpcap64t\n  Running command git clone --filter=blob:none --quiet https://github.com/0cc4m/hf_bleeding_edge/ /tmp/pip-req-build-xpcap64t\n  Resolved https://github.com/0cc4m/hf_bleeding_edge/ to commit f4c747d4c9f3143f7f290e35b4bf8edf6c08621c\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting auto-gptq==0.4.1+cu118 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 44))\n  Downloading https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.1/auto_gptq-0.4.1+cu118-cp310-cp310-linux_x86_64.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hIgnoring auto-gptq: markers 'sys_platform == \"win32\" and python_version == \"3.10\"' don't match your environment\nIgnoring auto-gptq: markers 'sys_platform == \"linux\" and python_version == \"3.8\"' don't match your environment\nIgnoring auto-gptq: markers 'sys_platform == \"win32\" and python_version == \"3.8\"' don't match your environment\nIgnoring windows-curses: markers 'sys_platform == \"win32\"' don't match your environment\nCollecting transformers[sentencepiece]==4.33.1 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 1))\n  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface_hub==0.16.4 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 2)) (0.16.4)\nCollecting optimum[onnxruntime]==1.12.0 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 3))\n  Downloading optimum-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.6/380.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors==0.3.3 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 4)) (0.3.3)\nRequirement already satisfied: Flask==2.3.3 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 5)) (2.3.3)\nCollecting Flask-SocketIO==5.3.2 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 6))\n  Downloading Flask_SocketIO-5.3.2-py3-none-any.whl (17 kB)\nCollecting python-socketio==5.7.2 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 7))\n  Downloading python_socketio-5.7.2-py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 8)) (2.31.0)\nRequirement already satisfied: torch==2.0.* in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 9)) (2.0.0)\nCollecting flask-cloudflared==0.0.10 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 10))\n  Downloading flask_cloudflared-0.0.10-py3-none-any.whl (5.9 kB)\nCollecting flask-ngrok (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 11))\n  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\nCollecting flask-cors (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 12))\n  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\nCollecting eventlet==0.33.3 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 13))\n  Downloading eventlet-0.33.3-py2.py3-none-any.whl (226 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting dnspython==2.2.1 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 14))\n  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting lupa==1.10 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 15))\n  Downloading lupa-1.10.tar.gz (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 16)) (3.4.3)\nCollecting bleach==4.1.0 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 17))\n  Downloading bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.9/157.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 18)) (3.20.3)\nCollecting accelerate==0.21.0 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 19))\n  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting flask-session==0.5.0 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 20))\n  Downloading flask_session-0.5.0-py3-none-any.whl (7.2 kB)\nRequirement already satisfied: marshmallow>=3.13 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 21)) (3.20.1)\nCollecting apispec-webframeworks (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 22))\n  Downloading apispec_webframeworks-0.5.2-py2.py3-none-any.whl (12 kB)\nCollecting loguru (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 23))\n  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 24)) (2.3.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 26)) (9.5.0)\nCollecting diffusers (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 27))\n  Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 28)) (5.9.3)\nCollecting ansi2html (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 29))\n  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\nCollecting flask_compress (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 30))\n  Downloading Flask_Compress-1.14-py3-none-any.whl (8.4 kB)\nCollecting ijson (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 31))\n  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting bitsandbytes==0.40.0.post4 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 32))\n  Downloading bitsandbytes-0.40.0.post4-py3-none-any.whl (101.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting ftfy (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 34))\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 35)) (0.25.1)\nCollecting pytest==7.2.2 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 36))\n  Downloading pytest-7.2.2-py3-none-any.whl (317 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.2/317.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytest-html==3.2.0 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 37))\n  Downloading pytest_html-3.2.0-py3-none-any.whl (16 kB)\nCollecting pytest-metadata==2.0.4 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 38))\n  Downloading pytest_metadata-2.0.4-py3-none-any.whl (9.9 kB)\nCollecting requests-mock==1.10.0 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 39))\n  Downloading requests_mock-1.10.0-py2.py3-none-any.whl (28 kB)\nCollecting einops (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 41))\n  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting peft==0.3.0 (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 42))\n  Downloading peft-0.3.0-py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 43)) (1.11.2)\nRequirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/tmp/KoboldAI/requirements.txt (line 49)) (11.4.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (3.12.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (4.66.1)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (0.1.99)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.16.4->-r /kaggle/tmp/KoboldAI/requirements.txt (line 2)) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.16.4->-r /kaggle/tmp/KoboldAI/requirements.txt (line 2)) (4.6.3)\nCollecting coloredlogs (from optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3))\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (1.12)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (2.1.0)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (1.14.1)\nCollecting onnxruntime>=1.11.0 (from optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3))\n  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting evaluate (from optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3))\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: Werkzeug>=2.3.7 in /opt/conda/lib/python3.10/site-packages (from Flask==2.3.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 5)) (2.3.7)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask==2.3.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 5)) (3.1.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask==2.3.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 5)) (2.1.2)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask==2.3.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 5)) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask==2.3.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 5)) (1.6.2)\nRequirement already satisfied: bidict>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from python-socketio==5.7.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 7)) (0.22.1)\nCollecting python-engineio>=4.3.0 (from python-socketio==5.7.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 7))\n  Downloading python_engineio-4.8.0-py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.*->-r /kaggle/tmp/KoboldAI/requirements.txt (line 9)) (3.1)\nRequirement already satisfied: greenlet>=0.3 in /opt/conda/lib/python3.10/site-packages (from eventlet==0.33.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 13)) (2.0.2)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from eventlet==0.33.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 13)) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach==4.1.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 17)) (0.5.1)\nCollecting cachelib (from flask-session==0.5.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 20))\n  Downloading cachelib-0.10.2-py3-none-any.whl (18 kB)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from pytest==7.2.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 36)) (23.1.0)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest==7.2.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 36)) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest==7.2.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 36)) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest==7.2.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 36)) (1.1.1)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest==7.2.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 36)) (2.0.1)\nCollecting py>=1.8.2 (from pytest-html==3.2.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 37))\n  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/tmp/KoboldAI/requirements.txt (line 8)) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/tmp/KoboldAI/requirements.txt (line 8)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/tmp/KoboldAI/requirements.txt (line 8)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->-r /kaggle/tmp/KoboldAI/requirements.txt (line 8)) (2023.7.22)\nCollecting apispec[yaml]>=2.0.0 (from apispec-webframeworks->-r /kaggle/tmp/KoboldAI/requirements.txt (line 22))\n  Downloading apispec-6.3.0-py3-none-any.whl (29 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers->-r /kaggle/tmp/KoboldAI/requirements.txt (line 27)) (6.7.0)\nCollecting brotli (from flask_compress->-r /kaggle/tmp/KoboldAI/requirements.txt (line 30))\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->-r /kaggle/tmp/KoboldAI/requirements.txt (line 34)) (0.2.6)\nCollecting typing (from hf-bleeding-edge==0.0.4->-r /kaggle/tmp/KoboldAI/requirements.txt (line 40))\n  Downloading typing-3.7.4.3.tar.gz (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting rouge (from auto-gptq==0.4.1+cu118->-r /kaggle/tmp/KoboldAI/requirements.txt (line 44))\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (2.0.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (0.70.15)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (0.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->Flask==2.3.3->-r /kaggle/tmp/KoboldAI/requirements.txt (line 5)) (2.1.3)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (23.5.26)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[sentencepiece]==4.33.1->-r /kaggle/tmp/KoboldAI/requirements.txt (line 1)) (3.0.9)\nCollecting simple-websocket>=0.10.0 (from python-engineio>=4.3.0->python-socketio==5.7.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 7))\n  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3))\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers->-r /kaggle/tmp/KoboldAI/requirements.txt (line 27)) (3.15.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (1.3.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (1.3.1)\nCollecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.3.0->python-socketio==5.7.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 7))\n  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[onnxruntime]==1.12.0->-r /kaggle/tmp/KoboldAI/requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: h11<1,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.3.0->python-socketio==5.7.2->-r /kaggle/tmp/KoboldAI/requirements.txt (line 7)) (0.14.0)\nBuilding wheels for collected packages: lupa, mkultra, hf-bleeding-edge, typing\n  Building wheel for lupa (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lupa: filename=lupa-1.10-cp310-cp310-linux_x86_64.whl size=262958 sha256=07d02400ac1c3ef5f8e20443e3215db34fe5a295c42e156bd726e2a4262d472d\n  Stored in directory: /root/.cache/pip/wheels/93/a3/25/eec3aaca044bc9ffd3a960dcaa92d4beaf874654b5cf632443\n  Building wheel for mkultra (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mkultra: filename=mkultra-0.1-py3-none-any.whl size=10897 sha256=f569f979dfc5a055ad5a1386f9f1e46c319b572136ad8cbc59153574a0ee4f73\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qdhnyqzk/wheels/1f/63/2e/bb2431c68bc2d4121376a2881f80f74f35e21ec6d0418b8b05\n  Building wheel for hf-bleeding-edge (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hf-bleeding-edge: filename=hf_bleeding_edge-0.0.4-py3-none-any.whl size=36571 sha256=440f3af1fc80cf47e721db0702c83470e4fb5da8520054406c061cca02f4392f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qdhnyqzk/wheels/0c/fd/03/bdbe700c1030eb8947375219de36b9a888a4718649c337d6c2\n  Building wheel for typing (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26305 sha256=116616426e6cac3efbf7f8d7219b70c17a9a6dd812f22d337edfb476a0f30272\n  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\nSuccessfully built lupa mkultra hf-bleeding-edge typing\nInstalling collected packages: mkultra, lupa, ijson, brotli, bitsandbytes, wsproto, typing, rouge, py, loguru, humanfriendly, ftfy, einops, dnspython, cachelib, ansi2html, simple-websocket, requests-mock, pytest, eventlet, coloredlogs, bleach, apispec, transformers, python-engineio, pytest-metadata, onnxruntime, flask-session, flask-ngrok, flask-cors, flask_compress, flask-cloudflared, diffusers, accelerate, python-socketio, pytest-html, peft, hf-bleeding-edge, apispec-webframeworks, optimum, Flask-SocketIO, evaluate, auto-gptq\n  Attempting uninstall: pytest\n    Found existing installation: pytest 7.4.1\n    Uninstalling pytest-7.4.1:\n      Successfully uninstalled pytest-7.4.1\n  Attempting uninstall: bleach\n    Found existing installation: bleach 6.0.0\n    Uninstalling bleach-6.0.0:\n      Successfully uninstalled bleach-6.0.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.22.0\n    Uninstalling accelerate-0.22.0:\n      Successfully uninstalled accelerate-0.22.0\nSuccessfully installed Flask-SocketIO-5.3.2 accelerate-0.21.0 ansi2html-1.8.0 apispec-6.3.0 apispec-webframeworks-0.5.2 auto-gptq-0.4.1+cu118 bitsandbytes-0.40.0.post4 bleach-4.1.0 brotli-1.1.0 cachelib-0.10.2 coloredlogs-15.0.1 diffusers-0.21.4 dnspython-2.2.1 einops-0.7.0 evaluate-0.4.1 eventlet-0.33.3 flask-cloudflared-0.0.10 flask-cors-4.0.0 flask-ngrok-0.0.25 flask-session-0.5.0 flask_compress-1.14 ftfy-6.1.1 hf-bleeding-edge-0.0.4 humanfriendly-10.0 ijson-3.2.3 loguru-0.7.2 lupa-1.10 mkultra-0.1 onnxruntime-1.16.1 optimum-1.12.0 peft-0.3.0 py-1.11.0 pytest-7.2.2 pytest-html-3.2.0 pytest-metadata-2.0.4 python-engineio-4.8.0 python-socketio-5.7.2 requests-mock-1.10.0 rouge-1.0.1 simple-websocket-1.0.0 transformers-4.33.1 typing-3.7.4.3 wsproto-1.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#!apt-get -o Dpkg::Options::=\"--force-confmiss\" install --reinstall netbase\n#!pip3 install -r kaggle/tmp/KoboldAI/requirements_mtj.txt","metadata":{"_uuid":"7ea9d0e9-f8a6-4133-b9f9-eb0eb003f4e4","_cell_guid":"0a13f6ba-3d4a-425b-b590-eaee5df1ad14","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-03T05:04:27.338739Z","iopub.execute_input":"2023-11-03T05:04:27.339136Z","iopub.status.idle":"2023-11-03T05:04:27.343905Z","shell.execute_reply.started":"2023-11-03T05:04:27.339099Z","shell.execute_reply":"2023-11-03T05:04:27.342775Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Everything under this point are executed every session","metadata":{"_uuid":"630dcf8d-aef9-4ba0-9a0b-4aba72d9659e","_cell_guid":"af2d25ad-cd15-4c54-9668-5899eee0895d","trusted":true}},{"cell_type":"markdown","source":"Enter your Ngrok authtoken below.","metadata":{"_uuid":"23f83c52-5a00-4f2a-98da-76c009203a44","_cell_guid":"f90e13a2-8faf-43e1-96cb-649a04993a4e","trusted":true}},{"cell_type":"code","source":"pickmodel = 'airoboros'  # airoboros or mythomax\n\nif pickmodel == 'airoboros':\n    model = 'jondurbin/airoboros-l2-13b-gpt4-m2.0'\nelif pickmodel == 'mythomax':\n    model = 'Gryphe/MythoMax-L2-13b'\nelse:\n    model = pickmodel\n\nprint(model)\n\nsplitlayers = 'gpu'  # gpu or cpu (never use cpu)\n\nif splitlayers == 'gpu':\n    modelpara = '\\\"{\\'0_Layers\\': \\'20\\', \\'1_Layers\\': \\'20\\'}\\\"'\nelif splitlayers == 'cpu':\n    modelpara = '\\\"{\\'0_Layers\\': \\'13\\', \\'1_Layers\\': \\'13\\', \\'CPU_Layers\\': \\'13\\'}\\\"'\nelse:\n    print(\"what are you doing put the damn option in\")\n    modelpara = None\n\nprint(modelpara)","metadata":{"_uuid":"41f0175b-613d-4d14-b035-f00876bbfc61","_cell_guid":"acd9585b-a428-4751-b95b-5cca602d89f6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-03T05:04:27.345533Z","iopub.execute_input":"2023-11-03T05:04:27.345889Z","iopub.status.idle":"2023-11-03T05:04:27.360064Z","shell.execute_reply.started":"2023-11-03T05:04:27.345854Z","shell.execute_reply":"2023-11-03T05:04:27.359093Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"jondurbin/airoboros-l2-13b-gpt4-m2.0\n\"{'0_Layers': '20', '1_Layers': '20'}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from pyngrok import ngrok\n!ngrok authtoken 2TJtNRx0yNmzCWMhIp9pGfpOAqC_7mbL2r4YJNJF9znrTkTEX\ntunnel = ngrok.connect(5000,\n                       domain=\"crack-ample-roughy.ngrok-free.app\")","metadata":{"_uuid":"0d5b5916-af27-4c37-ac8e-cb2f8ade503d","_cell_guid":"03c44326-55f0-4029-b2c4-c9680e8a2c88","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-03T05:04:27.362536Z","iopub.execute_input":"2023-11-03T05:04:27.362913Z","iopub.status.idle":"2023-11-03T05:04:29.336931Z","shell.execute_reply.started":"2023-11-03T05:04:27.362882Z","shell.execute_reply":"2023-11-03T05:04:29.335563Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml                                      \n","output_type":"stream"}]},{"cell_type":"markdown","source":"Leave the model below. You can select your model in kolbold ai.","metadata":{"_uuid":"739e0ceb-819c-4b76-9dba-3055cbdd2221","_cell_guid":"09063c8f-6230-474f-aeb7-f50717766343","trusted":true}},{"cell_type":"code","source":"#","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:04:29.338719Z","iopub.execute_input":"2023-11-03T05:04:29.339160Z","iopub.status.idle":"2023-11-03T05:04:29.345751Z","shell.execute_reply.started":"2023-11-03T05:04:29.339120Z","shell.execute_reply":"2023-11-03T05:04:29.344634Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(tunnel.public_url)\n!python /kaggle/tmp/KoboldAI/aiserver.py --quiet --model {model} --model_parameters {modelpara}","metadata":{"_uuid":"073188f7-c127-4e27-80b0-035f0211d2c2","_cell_guid":"1e52b374-ce97-4422-8404-259f445a0d35","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-03T05:04:29.347239Z","iopub.execute_input":"2023-11-03T05:04:29.348141Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"https://crack-ample-roughy.ngrok-free.app\n\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/cuda/lib')}\n  warn(msg)\nCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 118\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nColab Check: False, TPU: False\n\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mKAI Horde Models\u001b[0m\n\u001b[1mINFO      \u001b[0m | \u001b[32m__main__\u001b[0m:\u001b[32m<module>\u001b[0m:\u001b[32m729\u001b[0m - \u001b[1mWe loaded the following model backends: \nBasic Huggingface\nKoboldAI Old Colab Method\nHuggingface MTJ\nRead Only\nGooseAI\nLegacy GPTQ\nKoboldAI API\nOpenAI\nHuggingface\nHorde\u001b[0m\n\u001b[1mINFO      \u001b[0m | \u001b[32m__main__\u001b[0m:\u001b[32mgeneral_startup\u001b[0m:\u001b[32m1444\u001b[0m - \u001b[1mRunning on Repo: https://github.com/henk717/KoboldAI Branch: united\u001b[0m\n\u001b[32mMESSAGE   \u001b[0m | \u001b[32mWelcome to KoboldAI!\u001b[0m\n\u001b[32mMESSAGE   \u001b[0m | \u001b[32mYou have selected the following Model: jondurbin/airoboros-l2-13b-gpt4-m2.0\u001b[0m\n\nDownloading (…)lve/main/config.json: 100%|█████| 628/628 [00:00<00:00, 3.54MB/s]\u001b[A\nTODO: Allow config\n\u001b[1mINFO      \u001b[0m | \u001b[32mmodeling.inference_models.hf\u001b[0m:\u001b[32mset_input_parameters\u001b[0m:\u001b[32m198\u001b[0m - \u001b[1m{'0_Layers': '20', '1_Layers': '20', 'CPU_Layers': 0, 'Disk_Layers': 0, 'quantization': '4bit', 'id': 'jondurbin/airoboros-l2-13b-gpt4-m2.0', 'model': 'jondurbin/airoboros-l2-13b-gpt4-m2.0', 'path': None, 'menu_path': ''}\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mFlask\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mFlask\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mWebserver\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mWebserver\u001b[0m\n\u001b[32mMESSAGE   \u001b[0m | \u001b[32mWebserver started! You may now connect with a browser at http://127.0.0.1:5000\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[37mSearching \u001b[0m | \u001b[35mGPU support\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[32mFound     \u001b[0m | \u001b[35mGPU support\u001b[0m\n\nDownloading (…)model.bin.index.json: 100%|█| 33.4k/33.4k [00:00<00:00, 1.58MB/s]\u001b[A\n[aria2] Downloading model: 100%|##########| 26.0G/26.0G [02:33<00:00, 170MB/s] \nDownloading shards:   0%|                                 | 0/3 [00:00<?, ?it/s]\u001b[A\nDownloading shards: 100%|█████████████████████████| 3/3 [00:00<00:00, 23.40it/s]\u001b[A\n\nLoading checkpoint shards:   0%|                          | 0/3 [00:00<?, ?it/s]\u001b[A/opt/conda/lib/python3.10/site-packages/transformers/utils/bitsandbytes.py:17: FutureWarning: transformers.utils.bitsandbytes module is deprecated and will be removed in a future version. Please import bitsandbytes modules directly from transformers.integrations\n  warnings.warn(\nLoading model tensors: 100%|##########| 153/153 [01:05<00:00,  3.96it/s]\nLoading model tensors: 100%|##########| 155/155 [01:21<00:00,  1.88it/s].25s/it]\u001b[A\nLoading model tensors: 100%|##########| 95/95 [00:50<00:00,  1.09it/s]s].58s/it]\u001b[A\nLoading checkpoint shards: 100%|██████████████████| 3/3 [03:19<00:00, 66.50s/it]\u001b[A\n\n\nDownloading (…)neration_config.json: 100%|██████| 192/192 [00:00<00:00, 145kB/s]\u001b[A\u001b[A\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\nLoading model tensors: 100%|##########| 95/95 [00:51<00:00,  1.85it/s]\nDownloading (…)okenizer_config.json: 100%|█████| 749/749 [00:00<00:00, 5.39MB/s]\u001b[A\n\nDownloading tokenizer.model: 100%|███████████| 500k/500k [00:00<00:00, 9.36MB/s]\u001b[A\n\nDownloading (…)cial_tokens_map.json: 100%|█████| 438/438 [00:00<00:00, 2.45MB/s]\u001b[A\n\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mLUA bridge\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mLUA bridge\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[37mStarting  \u001b[0m | \u001b[35mLUA Scripts\u001b[0m\n\u001b[35mINIT      \u001b[0m | \u001b[32mOK        \u001b[0m | \u001b[35mLUA Scripts\u001b[0m\nSetting Seed\n","output_type":"stream"}]}]}